from dotenv import load_dotenv
load_dotenv()

import os
import gradio as gr
from gtts import gTTS
from pydub import AudioSegment

from farmer_doctor import encode_image, analyze_image_with_query
from chatbot.voice_of_farmer import transcribe_with_groq

# Language-based prompts
farmer_prompt_en = """
You are an experienced agriculture advisor helping a rural farmer. Analyze the image of the plant/crop and listen to their concern. 
Give a short, clear explanation of what the issue might be (e.g., pest, disease, dryness, etc.), and suggest simple steps to fix or manage it.
Avoid scientific jargon or long explanations. Just say what the issue is and what to do. 
DonтАЩt mention you are an AI. Speak naturally like a field expert guiding a real farmer. 
No numbers or special formatting, just a friendly, clear response.
"""

farmer_prompt_hi = """
рдЖрдк рдПрдХ рдЕрдиреБрднрд╡реА рдХреГрд╖рд┐ рд╕рд▓рд╛рд╣рдХрд╛рд░ рд╣реИрдВ рдЬреЛ рдПрдХ рдЧреНрд░рд╛рдореАрдг рдХрд┐рд╕рд╛рди рдХреА рдорджрдж рдХрд░ рд░рд╣реЗ рд╣реИрдВред рдкреМрдзреЗ/рдлрд╕рд▓ рдХреА рдЫрд╡рд┐ рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░реЗрдВ рдФрд░ рдЙрдирдХреА рдЪрд┐рдВрддрд╛ рд╕реБрдиреЗрдВред
рд╕рдВрдХреНрд╖реЗрдк рдореЗрдВ, рд╕реНрдкрд╖реНрдЯ рд░реВрдк рд╕реЗ рдмрддрд╛рдПрдВ рдХрд┐ рд╕рдорд╕реНрдпрд╛ рдХреНрдпрд╛ рд╣реЛ рд╕рдХрддреА рд╣реИ (рдЬреИрд╕реЗ рдХреАрдЯ, рд░реЛрдЧ, рд╕реВрдЦрд╛рдкрди рдЖрджрд┐), рдФрд░ рдЙрд╕реЗ рдареАрдХ рдХрд░рдиреЗ рдпрд╛ рдкреНрд░рдмрдВрдзрд┐рдд рдХрд░рдиреЗ рдХреЗ рдЖрд╕рд╛рди рдЙрдкрд╛рдп рд╕реБрдЭрд╛рдПрдВред
рд╡реИрдЬреНрдЮрд╛рдирд┐рдХ рд╢рдмреНрджреЛрдВ рдпрд╛ рд▓рдВрдмреЗ рд╡рд┐рд╡рд░рдг рд╕реЗ рдмрдЪреЗрдВред рдмрд╕ рд╕реНрдкрд╖реНрдЯ, рдЕрдиреМрдкрдЪрд╛рд░рд┐рдХ рднрд╛рд╖рд╛ рдореЗрдВ рдмрддрд╛рдПрдВ рдХрд┐ рд╕рдорд╕реНрдпрд╛ рдХреНрдпрд╛ рд╣реИ рдФрд░ рдХреНрдпрд╛ рдХрд░рдирд╛ рд╣реИред
рдЕрдкрдиреЗ рдЖрдк рдХреЛ AI рдХрд╣рдиреЗ рд╕реЗ рдмрдЪреЗрдВред рдПрдХ рдлреАрд▓реНрдб рдПрдХреНрд╕рдкрд░реНрдЯ рдХреА рддрд░рд╣ рдмрд╛рдд рдХрд░реЗрдВред
"""

# Text-to-speech
def text_to_speech_with_gtts(text, lang_code="en", output_mp3="output.mp3", output_wav="output.wav"):
    tts = gTTS(text=text, lang=lang_code, slow=False)
    tts.save(output_mp3)
    sound = AudioSegment.from_mp3(output_mp3)
    sound.export(output_wav, format="wav")
    return output_wav

# Core logic
def process_inputs(audio_filepath, image_filepath, language):
    prompt = farmer_prompt_en if language == "English" else farmer_prompt_hi
    lang_code = "en" if language == "English" else "hi"
    
    if audio_filepath:
        speech_text = transcribe_with_groq(
            GROQ_API_KEY=os.environ.get("GROQ_API_KEY"), 
            audio_filepath=audio_filepath,
            stt_model="whisper-large-v3"
        )
    else:
        speech_text = "No audio provided." if language == "English" else "рдХреЛрдИ рдСрдбрд┐рдпреЛ рдирд╣реАрдВ рдорд┐рд▓рд╛ред"

    if image_filepath:
        response = analyze_image_with_query(
            query=prompt + "\nFarmer's message: " + speech_text, 
            encoded_image=encode_image(image_filepath), 
            model="meta-llama/llama-4-scout-17b-16e-instruct"
        )
    else:
        response = "No plant image provided for analysis." if language == "English" else "рдкреМрдзреЗ рдХреА рдЫрд╡рд┐ рдирд╣реАрдВ рджреА рдЧрдИред"

    audio_output = text_to_speech_with_gtts(response, lang_code=lang_code)
    return speech_text, response, audio_output

# Styling (now includes font for Hindi)
css = """
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+Devanagari&display=swap');
body { background-color: #d9fdd3; }
.gradio-container {
    font-family: 'Segoe UI', 'Noto Sans Devanagari', sans-serif;
}
h1, label, .markdown-text-container {
    color: #205723;
    font-family: 'Segoe UI', 'Noto Sans Devanagari', sans-serif;
}
"""

# Gradio UI with Hindi font and side-by-side layout
with gr.Blocks(css=css) as demo:
    gr.Markdown("## ЁЯМ╛ **BHOOMI AI (Vision and Voice)** тАУ рдЦреЗрдд рдХрд╛ рдбреЙрдХреНрдЯрд░ рдЕрдм рдЖрдкрдХреА рдЬреЗрдм рдореЗрдВ")

    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### ЁЯУе рдЗрдирдкреБрдЯ / Input")
            language = gr.Dropdown(["English", "Hindi"], value="English", label="ЁЯМР Select Language / рднрд╛рд╖рд╛ рдЪреБрдиреЗрдВ")
            audio_input = gr.Audio(sources=["microphone"], type="filepath", label="ЁЯОЩя╕П Speak your crop issue / рдЕрдкрдиреА рд╕рдорд╕реНрдпрд╛ рдмреЛрд▓реЗрдВ")
            image_input = gr.Image(type="filepath", label="ЁЯМ┐ Upload plant image / рдкреМрдзреЗ рдХреА рдЫрд╡рд┐ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ")
            submit = gr.Button("ЁЯза Analyze / рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░реЗрдВ")

        with gr.Column(scale=1):
            gr.Markdown("### ЁЯУд рдкрд░рд┐рдгрд╛рдо / Output")
            transcribed_text = gr.Textbox(label="ЁЯЧгя╕П Transcription of Farmer's Voice / рдЖрд╡рд╛рдЬрд╝ рдХреА рд▓рд┐рдЦрд╛рд╡рдЯ")
            advice_text = gr.Textbox(label="ЁЯМ┐ Farming Advice / рдХреГрд╖рд┐ рд╕рд▓рд╛рд╣")
            spoken_audio = gr.Audio(label="ЁЯФК Spoken Advice / рдмреЛрд▓реЗ рдЧрдП рд╕реБрдЭрд╛рд╡", type="filepath")

    submit.click(
        process_inputs, 
        inputs=[audio_input, image_input, language], 
        outputs=[transcribed_text, advice_text, spoken_audio]
    )

demo.launch(debug=True)
